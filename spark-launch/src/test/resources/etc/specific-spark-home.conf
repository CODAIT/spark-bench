spark-bench = {
  spark-submit-config = [{
    spark-home = "/usr/iop/current/spark2-client/"
    spark-args = {
      master = "yarn"
    }
    suites-parallel = false
    workload-suites = [
      {
        descr = "Generate a dataset, then take that same dataset and write it out to Parquet format"
        benchmark-output = "/home/dev-user/emily/results-data-gen.csv"
        // We need to generate the dataset first through the data generator, then we take that dataset and convert it to Parquet.
        parallel = false
        workloads = [
          {
            name = "data-generation-kmeans"
            rows = 100000000
            cols = 24
            output = "hdfs:///tmp/kmeans-data.csv"
          },
          {
            name = "sql"
            queryStr = "select * from input"
            input = "hdfs:///tmp/kmeans-data.csv"
            output = "hdfs:///tmp/kmeans-data.parquet"
          }
        ]
      },
      {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "/home/dev-user/emily/results-sql.csv"
        parallel = false
        repeat = 10
        workloads = [
          {
            name = "sql"
            input = ["hdfs:///tmp/kmeans-data.csv", "hdfs:///tmp/kmeans-data.parquet"]
            queryStr = ["select * from input", "select `0`, `22` from input where `0` < -0.9"]
            cache = false
          }
        ]
      }
    ]
  }]
}
