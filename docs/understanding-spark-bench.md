# Understanding `spark-bench`

`spark-bench` is a flexible system for benchmarking and simulating Spark jobs. 

## Data Generation

`spark-bench` has the capability to generate data according to many different configurable generators. 
Generated data can be written to any storage addressable by Spark, including local files, hdfs, S3, etc.

In the current version of 
 
## Workloads

The atomic unit of organization in `spark-bench` is the workload. Workloads are standalone Spark jobs that read their input data, if any,
from disk, and write their output, if the user wants it, out to disk.

Some workloads are designed to exercise a particular algorithm implementation or a particular method. Others are designed to 
simulate Spark use cases such as multiple notebook users hitting a single Spark cluster.

### Types of Workloads
Some existing categories of workloads include:
- ML workloads: Logistic Regression, KMeans, etc.
- "Exercise" workloads: designed to examine one particular portion of the Spark pipeline. A good example is SparkPi, a very compute-heavy workload with no need to for disk IO.
- Simulation workloads: designed to simulate Spark usage cases such as notebooks

### Custom Workloads
https://github.com/ecurtin/spark-bench/issues/11 describes the plans to allow users to tie custom workloads into spark-bench. 
In the meantime, users will need to fork spark-bench and add their workloads into the code, as documented in the [developer guide](developer-guide.md)

### Parameters
| Name        | Required (y/n)| Description  |
| ------------- |-------------| -----|
| name       | yes | The name/type of workload. For example, "kmeans", "sparkpi", "logisticregression"... | 
| input      | yes, for some | The path (local, hdfs, S3, etc.) to the input dataset for the workload. Some workloads (ex: SparkPi) do not require input. |
| workloadresultsoutput | no | If the user wishes to keep the output of the workload (ex: the value of pi generated by SparkPi), they can specify a path here. |
| arguments specific to the workload | depends | Most workloads provide configuration arguments. Ex: Value of K for KMeans. |

### Output vs. WorkloadResultsOutput

***Output:*** The timing results, workload config, system config, and other benchmarking info. One row per workload.
***WorkloadResultsOutput:*** The output generated by the workload itself. Examples: the value of pi generated by SparkPi. 
The clusters generated by running KMeans. The model generated by running Logistic Regression.

In the configuration file, paths for ***output*** are set in the Suite (see more below). 
Paths for ***workloadresultsoutput*** paths are set in the workloads.

## Suites





## Spark-Contexts

