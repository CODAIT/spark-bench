<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
## Table of Contents

- [Spark-Bench Built-In Workloads](#spark-bench-built-in-workloads)
  - [Common Parameters For All Workloads](#common-parameters-for-all-workloads)
  - [Data Generators](#data-generators)
  - [Common Parameters For All Data Generator Workloads](#common-parameters-for-all-data-generator-workloads)
    - [Kmeans Data Generator](#kmeans-data-generator)
    - [Linear Regression Data Generator](#linear-regression-data-generator)
  - [Exercise Workloads](#exercise-workloads)
    - [SparkPi](#sparkpi)
    - [Sleep](#sleep)
  - [Machine Learning and Statistics Workloads](#machine-learning-and-statistics-workloads)
    - [KMeans](#kmeans)
    - [LogisticRegression](#logisticregression)
  - [SQL](#sql)
    - [SQL Workload](#sql-workload)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# Spark-Bench Built-In Workloads

## Common Parameters For All Workloads

| Name        | Required (y/n)| Description  |
| ------------- |-------------| -----|
| name       | yes | The name/type of workload. For example, "kmeans", "sparkpi", "logisticregression"... |
| input      | yes, for some | The path (local, hdfs, S3, etc.) to the input dataset for the workload. Some workloads (ex: SparkPi) do not require input. |
| output | no | If the user wishes to keep the output of the workload (ex: the value of pi generated by SparkPi), they can specify a path here. |

Remember, the benchmark output (e.g. how long it takes to run SparkPi) is not the same as the workload results (e.g. what is the approximate value of pi).
The benchmark output is collected from each run of each workload and output to a path specified by the suite.

## Data Generators

In spark-bench, data generators are just a different type of workload!

## Common Parameters For All Data Generator Workloads

| Name        | Required (y/n)| Description  |
| ------------- |-------------| -----|
| name       | yes | The name/type of workload. For example, "kmeans", "sparkpi", "logisticregression"... |
| rows      | yes | number of rows to generate |
| cols     | yes| number of columns to generate |
| output   | yes | If the user wishes to keep the output of the workload (ex: the value of pi generated by SparkPi), they can specify a path here. |


### Kmeans Data Generator

| Name    | Required (y/n)| Default  | Description |
| ------- |---------------| ---------| ------------|
| k      | no | 2 | number of clusters generated |
| scaling | no | 0.6 | scaling factor of the the dataset|
| partitions | no| 2 | number of partitions|

### Linear Regression Data Generator

| Name    | Required (y/n)| Default  |
| ------- |---------------| ---------|
| eps      | no | 2 |
| intercepts | no | 0.1 |
| partitions | no| 10 |


## Exercise Workloads

### SparkPi

Borrowing from the classic Spark example, this workload computes an approximation of pi.
From the Spark examples page: <https://spark.apache.org/examples.html>
```
Spark can also be used for compute-intensive tasks. This code estimates π
by "throwing darts" at a circle. We pick random points in the unit square
((0, 0) to (1,1)) and see how many fall in the unit circle. The fraction
should be π / 4, so we use this to get our estimate.
```

**Parameters**

| Name        | Required (y/n)| Default  | Description |
| ----------- |---------------| ---------| ------------|
| slices      | no | 2 | Number of partitions that will be spawned |


### Sleep

Sleeps the thread. Can be configured to sleep for
a specified number of milliseconds,
or for a random-not-to-exceed number of milliseconds,
or for a random  number of milliseconds less than 3600000L (one hour).

**Parameters**

| Name        | Required (y/n)| Default  | Description |
| ----------- |---------------| ---------| ------------|
| sleepms     | no |  | specific number of milliseconds the thread should sleep |
| maxsleepms  | no |  | sleep for a random number of milliseconds less than maxsleepms |

If neither sleepms nor maxsleepms are defined, the Sleep workload will default to sleeping
for a random number of milliseconds less than 3600000L (one hour).

## Machine Learning and Statistics Workloads

### KMeans

Runs the KMeans algorithm over the input dataset. `input` from the common parameters is required.

**Parameters**

| Name        | Required (y/n)| Default  | Description |
| ----------- |---------------| ---------| ------------|
| k     | no | 2 | number of clusters |
| seed  | no | 127L | initial values |
| maxiterations  | no | 2 | maximum number of times the algorithm should iterate |

### LogisticRegression

Runs LogisticRegression over the input datasets. `input` from the common parameters is required.

`input` in this case is the training dataset. The test dataset is specified by `testfile`.

**Parameters**

| Name        | Required (y/n)| Default  | Description |
| ----------- |---------------| ---------| ------------|
| testfile       | yes | --    | testing dataset |
| numpartitions  | no  | 32    | number of partitions |
| cacheenabled   | no  | false | whether or not the datasets are cached after being read from disk |


## SQL

### SQL Workload
Runs a SQL query over the input dataset. `input` from the common parameters is required.

The query string is required to use "input" as the name of the table. For example:
```sql
select * from input where SomeNumericField < 15
```

**Parameters**

| Name        | Required (y/n)| Default  | Description |
| ----------- |---------------| ---------| ------------|
| queryStr     | yes          | --    | the sql query to perform |
| cache        | no           | false | whether the dataset should be cached after being read from disk |

# Bring Your Own Workload

You can dynamically load a jar with your implementation of Workload.scala.

More documentation forthcoming.